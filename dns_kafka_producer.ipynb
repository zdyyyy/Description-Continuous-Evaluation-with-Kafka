{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed592b88",
   "metadata": {},
   "source": [
    "# Setup notebook to communicate with server and push information into Kafka Topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52adc5aa",
   "metadata": {},
   "source": [
    "Welcome, please run the following lines of code to connect to the kafka server, make sure to store the .csv file in the same folder where this notebooks is. Have fun and good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b1b6aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kafka in c:\\users\\jacky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.3.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f51d84c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kafka-python in c:\\users\\jacky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install kafka-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b65a16",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b2e6e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from kafka import KafkaProducer\n",
    "from datetime import datetime\n",
    "from json import dumps\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608ac49c",
   "metadata": {},
   "source": [
    "#### Connect to server and to topic to consume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca17593e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to bootstrap server\n"
     ]
    }
   ],
   "source": [
    "producer = KafkaProducer(bootstrap_servers=['localhost:9092'],\n",
    "                         value_serializer=lambda x: \n",
    "                         dumps(x).encode('utf-8'))\n",
    "if producer.bootstrap_connected():\n",
    "    print(f\"Successfully connected to bootstrap server\")\n",
    "else:\n",
    "    print(\"Couldn't connect to bootstrap server.\")\n",
    "\n",
    "TOPIC_NAME = \"ml-raw-dns\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98e7dab",
   "metadata": {},
   "source": [
    "#### Define the function to push the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fa755b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_message(producer_instance, topic, message):\n",
    "    producer_instance.send(topic, message)\n",
    "    producer_instance.flush()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc333756",
   "metadata": {},
   "source": [
    "#### Push the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1ab2e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "268065it [04:33, 979.03it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch took 0:04:33.815390 time for ingesting data\n",
      "Ingestion Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"Kafka_dataset.csv\") as f:\n",
    "    start_time = datetime.now()\n",
    "    for i, line in tqdm(enumerate(f)):\n",
    "        #print(i, line)\n",
    "        produce_message(producer_instance=producer, topic=TOPIC_NAME, message=line)\n",
    "    end_time = datetime.now()\n",
    "    print(f\"Batch took {end_time-start_time} time for ingesting data\")\n",
    "\n",
    "print(\"Ingestion Completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "a75b28f9753f4e2f1476ae5e5ad4b4ab71094e0d64ff40d9df34ddf691f3c573"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
